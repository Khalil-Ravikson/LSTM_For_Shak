{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAUAK3CnB0jVL7fjXH20t+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khalil-Ravikson/LSTM_For_Shak/blob/main/LSTM_For_Shak.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqLUdiNG8Dbo"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization, Activation\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop"
      ],
      "metadata": {
        "id": "u2rmPqvx8dtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a URL do arquivo\n",
        "url = 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt'\n",
        "\n",
        "# Baixa o arquivo para um diretório temporário e retorna o caminho local\n",
        "filepath = tf.keras.utils.get_file('shakespeare.txt', origin=url)\n",
        "\n",
        "print(f'O arquivo está salvo em: {filepath}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aP90wL069GY_",
        "outputId": "b6a4011c-30ba-4269-d583-b18dc4727a00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "O arquivo está salvo em: /root/.keras/datasets/shakespeare.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Abre o arquivo e lê o conteúdo para uma string\n",
        "with open(filepath, 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# Imprime os primeiros 500 caracteres para verificar\n",
        "print(f'Conteúdo do arquivo (primeiros 500 caracteres):\\n{text[:500]}')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Jq_0MSOR9kb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()"
      ],
      "metadata": {
        "id": "efmNrfoK-aCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qO0Gujq3-tJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleciona os caracteres do índice 300.000 até o 800.000\n",
        "subset_text = text[300000:800000]"
      ],
      "metadata": {
        "id": "cPk6uwkn-v9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "character = sorted(set(subset_text))\n",
        "print(f\"O vocabulário tem {len(character)} caracteres únicos.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "615CQtX0_Rqh",
        "outputId": "4aac8dfc-3e1f-4d31-dd67-3e70a82313ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O vocabulário tem 39 caracteres únicos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_index = {char: index for index, char in enumerate(character)}\n",
        "\n",
        "print(\"Exemplos do dicionário char_to_index:\")\n",
        "print(char_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMuM1HpU_Mmi",
        "outputId": "4c6a42c4-8392-4e4e-ecb0-7e78c36cb802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exemplos do dicionário char_to_index:\n",
            "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'a': 13, 'b': 14, 'c': 15, 'd': 16, 'e': 17, 'f': 18, 'g': 19, 'h': 20, 'i': 21, 'j': 22, 'k': 23, 'l': 24, 'm': 25, 'n': 26, 'o': 27, 'p': 28, 'q': 29, 'r': 30, 's': 31, 't': 32, 'u': 33, 'v': 34, 'w': 35, 'x': 36, 'y': 37, 'z': 38}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_char = {index: char for index, char in enumerate(character)}\n",
        "\n",
        "print(\"Exemplos do dicionário index_to_char:\")\n",
        "print(index_to_char)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcIaCQ15APAl",
        "outputId": "dfd8be5c-d431-453e-f4d0-39f5f4f50632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exemplos do dicionário index_to_char:\n",
            "{0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '&', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: '3', 10: ':', 11: ';', 12: '?', 13: 'a', 14: 'b', 15: 'c', 16: 'd', 17: 'e', 18: 'f', 19: 'g', 20: 'h', 21: 'i', 22: 'j', 23: 'k', 24: 'l', 25: 'm', 26: 'n', 27: 'o', 28: 'p', 29: 'q', 30: 'r', 31: 's', 32: 't', 33: 'u', 34: 'v', 35: 'w', 36: 'x', 37: 'y', 38: 'z'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 100\n",
        "step_size = 3\n"
      ],
      "metadata": {
        "id": "0L6ujJ0-AYsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "setence = []\n",
        "next_char = []\n",
        "\n",
        "for i in range(0, len(subset_text) - sequence_length, step_size):\n",
        "    setence.append(subset_text[i:i+sequence_length])\n",
        "    next_char.append(subset_text[i+sequence_length])\n",
        "\n",
        "print(f'Número de sequências: {len(setence)}')\n",
        "print(f'Exemplo de sequência de entrada: \"{setence[0]}\"')\n",
        "print(f'Exemplo de caractere de saída: \"{next_char[0]}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVFtutnvAc1N",
        "outputId": "c7347272-a940-4f71-fa99-ea8e9c1c435b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de sequências: 166634\n",
            "Exemplo de sequência de entrada: \" blunt,\n",
            "and rice ap thomas with a valiant crew;\n",
            "and many more of noble fame and worth:\n",
            "and towards l\"\n",
            "Exemplo de caractere de saída: \"o\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "setence_size = len(setence)\n",
        "num_sequences = len(character)\n",
        "\n",
        "# Inicializa as matrizes X e y com zeros\n",
        "X = np.zeros((setence_size, sequence_length, num_sequences ), dtype=np.bool_)\n",
        "y = np.zeros((setence_size,num_sequences), dtype=np.bool_)\n",
        "\n",
        "# Preenche as matrizes com os valores one-hot encoding\n",
        "for i, sentence in enumerate(setence):\n",
        "    for t, character in enumerate(sentence):\n",
        "        # Para X, a entrada one-hot é a sequência de caracteres\n",
        "        X[i, t, char_to_index[character]] = 1\n",
        "    # Para y, a saída one-hot é o caractere seguinte\n",
        "    y[i, char_to_index[next_char[i]]] = 1\n",
        "\n",
        "print(f'\\nFormato de X: {X.shape}')\n",
        "print(f'Formato de y: {y.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8RXiYXGCAc8",
        "outputId": "9443c2c7-46e0-404d-9f3f-ca62ae5f762a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Formato de X: (166634, 100, 39)\n",
            "Formato de y: (166634, 39)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defina as dimensões de entrada com base nos seus dados\n",
        "input_shape = (100, 39)  # (sequence_length, vocab_size)\n",
        "vocab_size = 39\n",
        "\n",
        "# 1. Crie o modelo sequencial\n",
        "model = Sequential()\n",
        "\n",
        "# 2. Adicione a camada LSTM\n",
        "# A primeira camada LSTM precisa da dimensão de entrada (input_shape)\n",
        "# 'return_sequences=True' é necessário se você for empilhar outra camada LSTM depois\n",
        "model.add(LSTM(256, input_shape=input_shape))\n",
        "\n",
        "# 3. Adicione a camada de saída (Dense)\n",
        "# A camada de saída tem o mesmo tamanho do vocabulário (39)\n",
        "# A função de ativação 'softmax' garante que a saída seja uma distribuição de probabilidade,\n",
        "# onde a soma de todas as previsões é 1.\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "# 4. Compile o modelo\n",
        "# 'categorical_crossentropy' é a função de perda ideal para problemas de classificação multi-classe\n",
        "# 'adam' é um otimizador popular e eficiente, mas testaremos 'RSMprop'\n",
        "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01))\n",
        "\n",
        "# Resumo do modelo\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "6DSuxJUUEnsw",
        "outputId": "7d43dd8e-6d69-4e7d-aa65-beb219941aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m303,104\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m)             │        \u001b[38;5;34m10,023\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">303,104</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,023</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m313,127\u001b[0m (1.19 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">313,127</span> (1.19 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m313,127\u001b[0m (1.19 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">313,127</span> (1.19 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, batch_size=128, epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1y9R5UefGF0g",
        "outputId": "b34c3d36-21b8-49c9-aaf8-5eb08b1af9c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m894s\u001b[0m 685ms/step - loss: 2.6320\n",
            "Epoch 2/20\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m884s\u001b[0m 679ms/step - loss: 1.7883\n",
            "Epoch 3/20\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m934s\u001b[0m 688ms/step - loss: 1.6134\n",
            "Epoch 4/20\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m910s\u001b[0m 679ms/step - loss: 1.5193\n",
            "Epoch 5/20\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m888s\u001b[0m 682ms/step - loss: 1.4583\n",
            "Epoch 6/20\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m919s\u001b[0m 680ms/step - loss: 1.6383\n",
            "Epoch 7/20\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m878s\u001b[0m 674ms/step - loss: 2.2943\n",
            "Epoch 8/20\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m885s\u001b[0m 680ms/step - loss: 2.1657\n",
            "Epoch 9/20\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m920s\u001b[0m 679ms/step - loss: 2.3212\n",
            "Epoch 10/20\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m878s\u001b[0m 674ms/step - loss: 2.5027\n",
            "Epoch 11/20\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m870s\u001b[0m 668ms/step - loss: 2.2868\n",
            "Epoch 12/20\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m941s\u001b[0m 683ms/step - loss: 2.2288\n",
            "Epoch 13/20\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m918s\u001b[0m 680ms/step - loss: 2.1693\n",
            "Epoch 14/20\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m891s\u001b[0m 684ms/step - loss: 2.1078\n",
            "Epoch 15/20\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m903s\u001b[0m 694ms/step - loss: 2.1001\n",
            "Epoch 16/20\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m910s\u001b[0m 685ms/step - loss: 2.0763\n",
            "Epoch 17/20\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m918s\u001b[0m 682ms/step - loss: 2.0319\n",
            "Epoch 18/20\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m909s\u001b[0m 672ms/step - loss: 2.0156\n",
            "Epoch 19/20\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m935s\u001b[0m 682ms/step - loss: 1.9829\n",
            "Epoch 20/20\n",
            "\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m882s\u001b[0m 677ms/step - loss: 1.9580\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7dada95f1a30>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"shaksp.keras\")"
      ],
      "metadata": {
        "id": "6rakt_2UPy_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Função de amostragem que escolhe um índice a partir de uma distribuição de probabilidade.\n",
        "\n",
        "    Args:\n",
        "        preds (np.ndarray): As probabilidades de previsão do modelo para cada caractere.\n",
        "                            (ndarray de 1 dimensão)\n",
        "        temperature (float): O fator de temperatura para ajustar a aleatoriedade da amostragem.\n",
        "\n",
        "    Returns:\n",
        "        int: O índice do caractere selecionado.\n",
        "    \"\"\"\n",
        "    # Converter as previsões para float64 para evitar problemas de precisão numérica\n",
        "    preds = np.asarray(preds).astype('float64') + 1e-10\n",
        "\n",
        "    # Aplicar a temperatura para modificar as probabilidades\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "\n",
        "    # Calcular as probabilidades após a temperatura\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "    # Gerar uma amostragem a partir da distribuição de probabilidade\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "\n",
        "    # Retornar o índice do caractere com a maior probabilidade na amostragem\n",
        "    return np.argmax(probas)\n"
      ],
      "metadata": {
        "id": "WVTvesf-P5Mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, length, temperature, char_to_index, index_to_char, vocab_size, subset_text, sequence_length):\n",
        "    \"\"\"\n",
        "    Gera texto a partir de uma semente aleatória.\n",
        "\n",
        "    Args:\n",
        "        model (keras.Model): O modelo LSTM treinado.\n",
        "        length (int): O número de caracteres a serem gerados.\n",
        "        temperature (float): O fator de temperatura para a amostragem.\n",
        "        char_to_index (dict): Dicionário que mapeia caracteres para índices.\n",
        "        index_to_char (dict): Dicionário que mapeia índices para caracteres.\n",
        "        vocab_size (int): O tamanho do vocabulário.\n",
        "        subset_text (str): O texto original de onde a semente será extraída.\n",
        "        sequence_length (int): O comprimento da sequência de treinamento.\n",
        "\n",
        "    Returns:\n",
        "        str: O texto gerado.\n",
        "    \"\"\"\n",
        "    # 1. Escolhe um índice de início aleatório para a semente\n",
        "    start_index = random.randint(0, len(subset_text) - sequence_length - 1)\n",
        "\n",
        "    # 2. Extrai a semente (texto inicial)\n",
        "    generated_text = subset_text[start_index: start_index + sequence_length]\n",
        "\n",
        "    # Imprime a semente para visualização\n",
        "    print(f'Semente de entrada aleatória: \"{generated_text}\"')\n",
        "\n",
        "    # 3. Loop de geração de texto\n",
        "    for i in range(length):\n",
        "        # 3.1. Pré-processa a string atual (generated_text) para o formato one-hot\n",
        "        x_pred = np.zeros((1, sequence_length, vocab_size))\n",
        "        for t, char in enumerate(generated_text):\n",
        "            if char in char_to_index:\n",
        "                x_pred[0, t, char_to_index[char]] = 1.0\n",
        "\n",
        "        # 3.2. Faz a previsão com o modelo\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "\n",
        "        # 3.3. Amostra o próximo caractere com a função de temperatura\n",
        "        next_index = sample(preds, temperature)\n",
        "        next_char = index_to_char[next_index]\n",
        "\n",
        "        # 3.4. Adiciona o caractere à string e move a janela\n",
        "        generated_text += next_char\n",
        "        generated_text = generated_text[1:]\n",
        "\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "1mGVMNk8Q2KL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Gerando texto com temperatura = 0.2 (mais conservador)...\")\n",
        "generated_low_temp = generate_text(\n",
        "    model,\n",
        "    length=500,\n",
        "    temperature=0.2,\n",
        "    char_to_index=char_to_index,\n",
        "    index_to_char=index_to_char,\n",
        "    vocab_size=vocab_size,\n",
        "    subset_text=subset_text,\n",
        "    sequence_length=100\n",
        ")\n",
        "print(generated_low_temp)\n",
        "\n",
        "print(\"\\nGerando texto com temperatura = 0.8 (mais criativo)...\")\n",
        "generated_high_temp = generate_text(\n",
        "    model,\n",
        "    length=500,\n",
        "    temperature=0.8,\n",
        "    char_to_index=char_to_index,\n",
        "    index_to_char=index_to_char,\n",
        "    vocab_size=vocab_size,\n",
        "    subset_text=subset_text,\n",
        "    sequence_length=100\n",
        ")\n",
        "print(generated_high_temp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvMLbpguR2RJ",
        "outputId": "0e3cb144-83ac-4edc-f05d-b6f4bc81f663"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gerando texto com temperatura = 0.2 (mais conservador)...\n",
            "Semente de entrada aleatória: \"ht;\n",
            "and but thou love me, let them find me here:\n",
            "my life were better ended by their hate,\n",
            "than death\"\n",
            "\n",
            "and romeo: in the revem.\n",
            "\n",
            "romeo:\n",
            "here sor some starrive.\n",
            "\n",
            "romeo:\n",
            "no frear this sor.\n",
            "\n",
            "romeo:\n",
            "and so \n",
            "\n",
            "Gerando texto com temperatura = 0.8 (mais criativo)...\n",
            "Semente de entrada aleatória: \"cester:\n",
            "now tell me, brother clarence, what think you\n",
            "of this new marriage with the lady grey?\n",
            "hath \"\n",
            "not my friends; for many and is all shall of an is ifmor!\n",
            "\n",
            "king how sonone we\n",
            "broes was richard to m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nGerando texto com temperatura = 0.9 (mais )...\")\n",
        "generated_high_temp = generate_text(\n",
        "    model,\n",
        "    length=500,\n",
        "    temperature=0.9,\n",
        "    char_to_index=char_to_index,\n",
        "    index_to_char=index_to_char,\n",
        "    vocab_size=vocab_size,\n",
        "    subset_text=subset_text,\n",
        "    sequence_length=100\n",
        ")\n",
        "print(generated_high_temp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pvV3ce4TlsS",
        "outputId": "d6936382-ee91-44e5-fa81-822ede64e2e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gerando texto com temperatura = 0.9 (mais )...\n",
            "Semente de entrada aleatória: \"lows with thee for our day of doom.\n",
            "this ague fit of fear is over-blown;\n",
            "an easy task it is to win o\"\n",
            " a brood and bine richire cland\n",
            "to to man:\n",
            "for wives srave\n",
            "shoning now of banave.\n",
            "\n",
            "nor--\n",
            "aumer,\n",
            "swan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_RqFM6YfRutr"
      }
    }
  ]
}